# -*- coding: utf-8 -*-
"""LDA GENSIM MALLET.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oahJp1Ck_OSMJDSh20sW8TsQWaKtLNI0
"""

import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfTransformer
import matplotlib.pyplot as plt
from numpy import array

''' untuk memanggil dan melihat data'''
data = pd.read_excel('/content/data_netral.xlsx')   # jangan lupa ganti jalur data setiap ganti data
data.head()

''' membuat data menjadi list teks '''

text = data['clean_teks']
text_list =  [i.split() for i in text]
print(len(text_list))
print(text_list)

'''Tokenisasi kata yang disesuaikan dengan algoritma LDA agar dapat di proses'''

def tokenize(text):
    tokens = re.split('\W+', text)
    return tokens

data['token'] = data['clean_teks'].apply(lambda x: tokenize(x.lower()))
data.to_csv("data_tokenize.csv", sep=',')
data.head()

'''memanggil data baru'''
data = pd.read_csv('data_tokenize.csv')
data.head()

from sklearn.feature_extraction.text import CountVectorizer
count_vectorizer = CountVectorizer(encoding='latin-1', ngram_range=(1, 1), tokenizer=None, analyzer = 'word')
countvec = count_vectorizer.fit_transform(data.token).toarray()
countvec

countvec2 = pd.DataFrame(countvec)
countvec2

kata_kata = count_vectorizer.get_feature_names_out()
countvec3 = pd.DataFrame(countvec, columns=kata_kata)
countvec3

transform = TfidfTransformer(norm=None, use_idf=True, smooth_idf=False, sublinear_tf=False)
tfidf = transform.fit_transform(countvec)
tfidf

tfidf1 = tfidf.toarray()
tfidf2 = pd.DataFrame(tfidf1)
tfidf2

kata_kata = count_vectorizer.get_feature_names_out()
df = pd.DataFrame(tfidf1, columns=kata_kata)
df

from gensim.models import Phrases

bigram = Phrases(text_list, min_count=100)
trigram = Phrases(bigram[text_list])

for idx in range(len(text_list)):
    for token in bigram[text_list[idx]]:
        if '_' in token:

            text_list[idx].append(token)
    for token in trigram[text_list[idx]]:
        if '_' in token:

            text_list[idx].append(token)

from gensim import corpora, models
dictionary = corpora.Dictionary(text_list)
dictionary.filter_extremes(no_below=5, no_above=0.2)
print(dictionary)

'''Membuat corpus dengan fungsi doc2bow mengubah dokumen (daftar kata) ke dalam format kumpulan kata'''

doc_term_matrix = [dictionary.doc2bow(doc) for doc in text_list]


'''Fungsi doc2bow() hanya menghitung jumlah kemunculan setiap kata yang berbeda,
mengonversi kata menjadi id kata bilangan bulatnya dan mengembalikan hasilnya sebagai vektor renggang.
Oleh karena itu, vektor renggang [(0, 1), (1, 1)] berbunyi: dalam dokumen “Interaksi manusia dan komputer”,
kata komputer (id 0) dan manusia (id 1) muncul satu kali;
sepuluh kata kamus lainnya muncul (secara implisit) nol kali.'''

print(len(doc_term_matrix))
print(doc_term_matrix[100])

tfidf = models.TfidfModel(doc_term_matrix) #build TF-IDF model
corpus_tfidf = tfidf[doc_term_matrix]

"""## **INSTAL JAVA MALLET UNTUK CGS**"""

import os       #importing os to set environment variable
def install_java():
  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk
  os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"     #set environment variable
  !java -version       #check java version
install_java()

!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip
!unzip mallet-2.0.8.zip

!pip install --upgrade gensim==3.8

os.environ['MALLET_HOME'] = '/content/mallet-2.0.8'
mallet_path = '/content/mallet-2.0.8/bin/mallet'

''' Install library gensim LDA mallet'''

import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models.wrappers import LdaMallet
from gensim.models.coherencemodel import CoherenceModel
from gensim import similarities
import os.path
import re
import glob

''' Membuat fungsi untuk menghitung nilai koherensi'''

def compute_coherence_values(dictionary, corpus, texts, limit, start, step):
    coherence_values = []
    model_list = []
    for num_topics in range(start, limit, step):
        model = LdaMallet(mallet_path, corpus=corpus, id2word=dictionary, num_topics=num_topics, iterations=100)
        model_list.append(model)
        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='u_mass')
        coherence_values.append(coherencemodel.get_coherence())

    return model_list, coherence_values

start=1
limit=11
step=1
model_list, coherence_values = compute_coherence_values(dictionary, corpus=corpus_tfidf,
                                                        texts=text_list, start=start, limit=limit, step=step)


x = range(start, limit, step)
plt.plot(x, coherence_values)
plt.xlabel("Num Topics")
plt.ylabel("Coherence score")
plt.legend(("coherence_values"), loc='best')
plt.show()

'''Print the coherence scores'''

for m, cv in zip(x, coherence_values):
    print("Num Topics =", m, " has Coherence Value of", round(cv, 15))

model =  gensim.models.wrappers.ldamallet.LdaMallet(mallet_path, corpus=corpus_tfidf, id2word=dictionary, num_topics=10) # num_topics diganti sesuai nilai coherence tertinggi
lda_gensim = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(model, iterations=1000)

for idx, topic in lda_gensim.print_topics(-1):
    print('Topic: {} Word: {}'.format(idx, topic))

top_words_per_topic = []
for t in range(model.num_topics):
    top_words_per_topic.extend([(t, ) + x for x in model.show_topic(t, topn = 10)])


df = pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word','P']).to_csv("/content/top_words_topik_netral.csv")

'''untuk melihat data probabilitas words topik'''
top_words_topic = pd.read_csv('/content/top_words_topik_netral.csv')
top_words_topic.head(10)

'''membuat wordcloud per topik'''
from wordcloud import WordCloud
for topic_id, topic in enumerate(model.print_topics(num_topics=10, num_words=20)):
    topic_words = " ".join([word.split("*")[1].strip() for word in topic[1].split(" + ")])
    wordcloud = WordCloud(width=800, height=800, random_state=21, max_font_size=110).generate(topic_words)
    plt.figure()
    plt.imshow(wordcloud, interpolation="bilinear")
    plt.axis("off")
    plt.title("Topic: {}".format(topic_id))
    plt.show()

"""## **PyDlavis Visual**"""

!pip install pyldavis==3.2.1
import pyLDAvis.gensim
import pickle
import pyLDAvis

'''Membuat Visualisasi '''
pyLDAvis.enable_notebook()
pyLDAvis.gensim.prepare(lda_gensim, corpus_tfidf, dictionary)